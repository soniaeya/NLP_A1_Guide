{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soniaeya/NLP_A1_Guide/blob/master/Copy_of_assignment1_guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rqxJ_b9-uD"
      },
      "source": [
        "## Assigment 2: Word2vec and CBOW âš¡\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68lLjeyXEmaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWpKZPpdZcV8"
      },
      "source": [
        "In this assignment, we will guide you through the process of implementing Continous Bag Of Words (CBOW) using PyTorch, providing step-by-step instructions, code snippets, and explanations to aid your understanding. By the end of this assignment, you will have a solid grasp of Word2Vec's mechanics and be equipped to apply this knowledge to a wide range of NLP tasks.\n",
        "\n",
        "Let's embark on this journey to unlock the power of word embeddings with Word2Vec and PyTorch!\n",
        "\n",
        "This [guide](https://pytorch.org/tutorials/beginner/basics/intro.html) might come in handy to understand how Pytorch works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-kso1_rb2SM"
      },
      "source": [
        "Let's start by installing the needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aCFYPXdv_qZr",
        "outputId": "225d1706-6a40-4b49-ec21-f4c3eeb94f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WaXq72-9S-__"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AADnCtQddOYv"
      },
      "source": [
        "In this assigment we will use the dataset *text8*. This dataset is composed of textual content extracted from Wikipedia articles which hopefully will lead to good embeddings when input in CBOW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZyk8pYS9xOJ"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "dataset = list(api.load(\"text8\"))[0:10] #We trim the dataset to make training as long. Feel free to change this based on your resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eia3XW39jWP"
      },
      "source": [
        "Let's have a look at a datapoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pkSsdyq9YHT"
      },
      "outputs": [],
      "source": [
        "(\" \").join(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normally we would need to do some data preprocessing in order to clean our dataset but lucky for you the professor chose a pretty and clean dataset so you don't have to ðŸ˜‰"
      ],
      "metadata": {
        "id": "s6I-utm7mh_N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxUbk8nyTmu"
      },
      "source": [
        "Let's start to get more on topic. If you remember, Word2Vec has a specific way of generating each vector.\n",
        "![Captura de pantalla 2024-05-21 161613.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "The embedding is based on the surrounding words (before and after) taken as context. In the case of CBOW, we input the surrounding words to our neural network and expect that it predicts the middle word. Let's format our dataset to meet the needs of the neural network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oysoGd4Wxq8I"
      },
      "source": [
        "Since our neural networks can't understand strings we have to turn these strings into integers. In this case, we can use the one hot encodings to represent the words, so we will need the mapping: word -> one-hot-encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20IvUrxpwDL-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def create_word_to_index(vocab_list):\n",
        "  \"\"\" Method that creates dictionary that maps words to an index.\n",
        "  Arguments\n",
        "  ---------\n",
        "  vocab_list : list(String)\n",
        "    List of words in the vocabulary\n",
        "  Returns\n",
        "  -------\n",
        "  word_to_index : Dictionary\n",
        "    Dictionary mapping words to index with format {word:index}\n",
        "  \"\"\"\n",
        "  word_to_index = {}\n",
        "\n",
        "  for i,word in enumerate(vocab_list):\n",
        "    word_to_index[word] = i\n",
        "  return word_to_index\n",
        "\n",
        "vocab_list = list(set(word for sentence in dataset for word in sentence))\n",
        "word_to_index = create_word_to_index(vocab_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OkVuGeFQ9Bk"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(dataset, window_size,word_to_index):\n",
        "  \"\"\" Method to generate training dataset for CBOW.\n",
        "  Arguments\n",
        "  ---------\n",
        "  data : String\n",
        "     Training dataset\n",
        "  window_size : int\n",
        "     Size of the context window\n",
        "  word_to_index : Dictionary\n",
        "     Dictionary mapping words to index with format {word:index}\n",
        "  Returns\n",
        "  -------\n",
        "  surroundings : N x W Tensor\n",
        "      Tensor with index of surrounding words, with N being the number of samples and W being the window size\n",
        "  targets : Tensor\n",
        "      Tensor with index of target word\n",
        "  \"\"\"\n",
        "  surroundings= []\n",
        "  targets = []\n",
        "\n",
        "  for data in dataset:\n",
        "    for i in range(window_size,len(data)-window_size): # i = idx of target word\n",
        "    # j iterates through the window range, but skips i, the idx of the target word\n",
        "    # data[j] are the words surrounding the target word\n",
        "    # word_to_index[data[j]] are the indexes of the surrounding words\n",
        "    # surrounding is a dictionary of the surrounding word indexes\n",
        "\n",
        "      surrounding = [word_to_index[data[j]] for j in range (i - window_size, i + window_size + 1) if j != i] #get indexes of surrounding words in a list\n",
        "      surrounding = torch.tensor(surrounding)\n",
        "      target = word_to_index[data[i]] #get index of target word\n",
        "      surroundings.append(surrounding)\n",
        "      targets.append(target)\n",
        "\n",
        "  surroundings = torch.stack(surroundings)\n",
        "  targets = torch.tensor(targets)\n",
        "  return surroundings, targets\n",
        "\n",
        "\n",
        "WINDOW_SIZE = 2\n",
        "surroundings, targets = generate_dataset(dataset,WINDOW_SIZE,word_to_index)\n",
        "generate_dataset(dataset,WINDOW_SIZE,word_to_index)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OYFIK0g0YsI"
      },
      "source": [
        "With our dataset ready we can finally create our Neural Network. The idea is to replicate what Mikolov did in 2013 (see slides of Word2Vec)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKDcC75jzaXz"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim=300):\n",
        "    \"\"\" Class to define the CBOW model\n",
        "    Attributes\n",
        "    ---------\n",
        "    device : device\n",
        "      Device where the model will be trained (gpu preferably)\n",
        "    vocab_size : int\n",
        "      Size of the vocabulary\n",
        "    embed_dim : int\n",
        "      Size of the embedding layer\n",
        "    hidden_dim : int\n",
        "      Size of the hidden layer\n",
        "\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "    self.vocab_size = vocab_size # input size\n",
        "    self.embed_dim = embed_dim\n",
        "    self.hidden_dim = 128 # Define hidden_dim before using it\n",
        "\n",
        "    self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_dim)\n",
        "    self.linear_in = nn.Linear(self.embed_dim, self.hidden_dim, bias=False)# Linear layer that encodes one-hot-encoding to embedding dimension. Remember Mikolov's implementation had NO BIAS\n",
        "    self.linear_out = nn.Linear(self.hidden_dim, self.vocab_size, bias=False)# Linear layer that decodes from embedding dimension to vocab dimension. Remember Mikolov's implementation had NO BIAS\n",
        "\n",
        "  def forward(self, x):\n",
        "    emb = self.embedding(x) #pass input (indices of surrounding words) through embedding layer\n",
        "    average = torch.mean(emb, dim = 1) #average embeddings\n",
        "    out = self.linear_in(average)  #pass through linear layer\n",
        "    out = self.linear_out(out) #pass through output linear layer\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need an important function that creates one hot encoding vectors based on our surrounding word's indexes"
      ],
      "metadata": {
        "id": "Hp7Z3KGw_vIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_from_surroundings(surroundings,window_size, vocab_size):\n",
        "  \"\"\" Method to create one hot encodings for the surrounding words.\n",
        "  Arguments\n",
        "  ---------\n",
        "  surroundings : N x (Wx2) Tensor\n",
        "     Tensor with index of surrounding words, with N being the number of samples and W being the window size\n",
        "  vocab_size : int\n",
        "     Size of the vocabulary\n",
        "  Returns\n",
        "  -------\n",
        "  one_hot_surroundings : N x (Wx2) x V Tensor\n",
        "      Tensor with one hot encodings of surrounding words, with N being the number of samples, W being the window size and V being the vocabulary size\n",
        "  \"\"\"\n",
        "  one_hot_surr = torch.nn.functional.one_hot(surroundings, num_classes=vocab_size)\n",
        "  return one_hot_surr\n"
      ],
      "metadata": {
        "id": "AqaffIc_9l5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if your previous function is correct\n",
        "index= [[2,3,7,8],[0,1,9,5]]\n",
        "index_tensor = torch.tensor(index).to(device)\n",
        "answer = torch.tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
        "\n",
        "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
        "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]], device=device)\n",
        "\n",
        "prediction = one_hot_from_surroundings(index_tensor,2,10)\n",
        "assert prediction.shape == torch.Size([2, 4, 10]), \"Make sure the result has shape NUM_EXAMPLES X WINDOW_SIZE*2 X VOCAB_SIZE\"\n",
        "assert torch.equal(prediction,answer), \"Wrong implementation of one_hot_from_surroundings method\"\n",
        "print(\"Good Job!\")"
      ],
      "metadata": {
        "id": "ON_SHTKf-bY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are finally ready to train"
      ],
      "metadata": {
        "id": "j9swEtZqAtVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F9PVmiIgsXW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, random_split\n",
        "#creation of dataloader for training\n",
        "full_dataset = list(zip(surroundings,targets))\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=128,shuffle=True) #Here please change batch size depending of your GPU capacities (if GPU runs out of memory lower batch_size)\n",
        "val_dataloader=DataLoader(val_dataset,batch_size=128,shuffle=False) #Here please change batch size depending of your GPU capacities (if GPU runs out of memory lower batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyMPIPX-51l8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #CAUTION: RUN THIS CODE WITH GPU, CPU WILL TAKE TOO LONG\n",
        "EMB_DIM = 300\n",
        "CBOW_MODEL = CBOW(len(word_to_index), embed_dim= EMB_DIM).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(CBOW_MODEL.parameters(), lr=0.001)\n",
        "EPOCHS = 5\n",
        "\n",
        "#BE PATIENT: This code can take up to 1 hours for a batch size of 64 and 5 epochs\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-3):\n",
        "  total_loss = 0\n",
        "  i=0\n",
        "  for surr, tar in tqdm(train_dataloader,\"Training\"):\n",
        "      # TODO complete\n",
        "      surr, tar = surr.to(device), tar.to(device)\n",
        "      one_hot_surr = one_hot_from_surroundings(surr,WINDOW_SIZE, len(word_to_index)) # Remove this line\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      log_probs = model(surr) # Pass indices through model\n",
        "\n",
        "      loss= loss_function(log_probs,tar)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return total_loss/len(train_dataloader)\n",
        "def evaluate_model(model, val_loader):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "      for surr, tar in tqdm(val_loader, \"Validation\"):\n",
        "          surr, tar = surr.to(device), tar.to(device)\n",
        "          one_hot_surr = one_hot_from_surroundings(surr,WINDOW_SIZE, len(word_to_index)) # Remove this line\n",
        "\n",
        "          log_probs = model(surr) # Pass indices through model\n",
        "\n",
        "          loss= loss_function(log_probs,tar)\n",
        "          total_loss += loss.item()\n",
        "  return total_loss/len(val_loader)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = train_model(CBOW_MODEL, train_dataloader, val_dataloader, epochs=1, lr=0.001)\n",
        "  val_loss = evaluate_model(CBOW_MODEL, val_dataloader)\n",
        "  print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMjs6zu63bnh"
      },
      "source": [
        "## Let's test it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rarP3Yw3eCW"
      },
      "source": [
        "Now that we hopefully have good embeddings we can put them to the test. Let's start by creating some useful functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xJndx_85UJeY"
      },
      "outputs": [],
      "source": [
        "def create_word_to_embedding (vocab_list, model,word_to_index):\n",
        "  \"\"\" Method to get create dictionary that maps a word to it's embedding vector.\n",
        "  Arguments\n",
        "  ---------\n",
        "  word : String\n",
        "     Word given\n",
        "  model : NN.module\n",
        "     CBOW model\n",
        "  word_to_index : Dictionary\n",
        "     Dictionary mapping words to index with format {word:index}\n",
        "  Returns\n",
        "  -------\n",
        "  word_embedding : Tensor\n",
        "      Embedding vector for the given word\n",
        "    \"\"\"\n",
        "  embedding_weights = model.embedding.weight # Get the weights of the embedding layer (remove .detach() and .cpu())\n",
        "  word_to_embedding = {}\n",
        "  for word in vocab_list:\n",
        "    index=  word_to_index[word] # Get word index\n",
        "    word_embedding = embedding_weights[index, :] # Extract the embedding vector for the given word index. This is done by getting the row of the index specified\n",
        "    word_to_embedding[word] = word_embedding\n",
        "\n",
        "  return word_to_embedding\n",
        "\n",
        "word_to_embedding = create_word_to_embedding(vocab_list,CBOW_MODEL,word_to_index)\n",
        "if 'study' in word_to_embedding:\n",
        "  print(\"Embedding of word 'study'\", word_to_embedding['study'])\n",
        "else:\n",
        "  print(\"Word 'study' not found in the vocabulary.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will test how good our word2vec model is by testing the embeddings on the downstream task of sentiment analysis of movies ðŸŽ¥\n",
        "\n",
        "Let's first import and download this dataset.\n"
      ],
      "metadata": {
        "id": "_d_EwIyfptj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "def decode_review(word_index, review):\n",
        "  decoded_review = \" \".join([reverse_word_index.get(i - 3, \"\") for i in review])\n",
        "  return decoded_review\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels)= imdb.load_data(num_words=10000)\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "# We will trim the dataset to not make training to long, feel free to change this based on your resources\n",
        "train_data = train_data[:10000]\n",
        "train_labels = train_labels[:10000]\n",
        "test_data = test_data[:2000]\n",
        "test_labels = test_labels[:2000]\n",
        "\n",
        "#Decode data\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "train_data = [decode_review(reverse_word_index,x) for x in train_data]\n",
        "test_data = [decode_review(reverse_word_index,x) for x in test_data]"
      ],
      "metadata": {
        "id": "mPK_JPPYVY4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a simple Sentiment classifier that will use our embeddings from our CBOW model. The model input will be an average of the word embeddings of the review and the output will be a binary: positiveðŸ™‚ or negativeðŸ˜ž."
      ],
      "metadata": {
        "id": "ubc_mCGE62JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating our Dataloaders"
      ],
      "metadata": {
        "id": "207hqm-ZC95U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, labels):\n",
        "        self.reviews = reviews\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.reviews[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def get_review_embedding(review):\n",
        "  \"\"\" Method to get the embedding vector for a given review.\n",
        "  Arguments\n",
        "  ---------\n",
        "  review : String\n",
        "     Review given\n",
        "  model : NN.module\n",
        "     CBOW model\n",
        "  word_to_index : Dictionary\n",
        "     Dictionary mapping words to index with format {word:index}\n",
        "  Returns\n",
        "  -------\n",
        "  review_embedding : Tensor\n",
        "      Embedding vector for the given review\n",
        "  \"\"\"\n",
        "  # TODO write a function that gets sentence embedding by averaging the embeddings of the words in the review (only take into account words in vocab)\n",
        "  words = review.split()\n",
        "  sum_embeddings = torch.zeros(list(word_to_embedding.values())[0].shape, device=device, requires_grad=True) # Explicitly set requires_grad=True\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if word in word_to_embedding:\n",
        "      # Ensure embedding is on the correct device and add to sum_embeddings\n",
        "      # Use .clone() to avoid modifying the original tensor in word_to_embedding\n",
        "      sum_embeddings = sum_embeddings + word_to_embedding[word].to(device)\n",
        "      count += 1\n",
        "  if count > 0:\n",
        "    review_embedding = sum_embeddings / count\n",
        "  else:\n",
        "    # Return a zero vector with requires_grad=True\n",
        "    review_embedding = torch.zeros(list(word_to_embedding.values())[0].shape, device=device, requires_grad=True)\n",
        "\n",
        "  return review_embedding\n",
        "\n",
        "\n",
        "def create_dataloader_imdb(train_data, train_labels, test_data, test_labels, batch_size= 64):\n",
        "  \"\"\" Method to create dataloaders for the IMDB dataset\n",
        "  Arguments\n",
        "  ---------\n",
        "  train_data : List\n",
        "     List of reviews for training\n",
        "     train_labels : List\n",
        "     List of labels for training\n",
        "  test_data : List\n",
        "     List of reviews for testing\n",
        "  test_labels : List\n",
        "     List of labels for testing\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  \"\"\"\n",
        "  train_dataset = ReviewDataset(train_data, train_labels)\n",
        "  test_dataset = ReviewDataset(test_data, test_labels)\n",
        "\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "  test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
        "  return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "train_dataloader_imd , test_dataloader_imd = create_dataloader_imdb(train_data, train_labels, test_data, test_labels)"
      ],
      "metadata": {
        "id": "UPj6em3dDCXU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a very simple MLP for this classification problem"
      ],
      "metadata": {
        "id": "aYly1Y6YCGJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrzjadMnGa8C"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim=128, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TODO complete forward\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the fun part, time to train"
      ],
      "metadata": {
        "id": "49_1rzXRCViG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #CAUTION: RUN THIS CODE WITH GPU, CPU WILL TAKE TOO LONG\n",
        "SENT_MODEL = SentimentClassifier(embedding_dim=EMB_DIM).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(SENT_MODEL.parameters(), lr=0.001)\n",
        "EPOCHS = 5\n",
        "\n",
        "#BE PATIENT: This code can take up to 1 hours for a batch size of 64 and 5 epochs\n",
        "\n",
        "def train_model(model, train_loader):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for reviews, y in tqdm(train_loader,\"Training\"):\n",
        "    # Calculate review embeddings dynamically with gradient tracking\n",
        "    X = torch.stack([get_review_embedding(review) for review in reviews]).to(device)\n",
        "    y = y.to(device) # Move labels to device\n",
        "\n",
        "    optimizer.zero_grad() # Zero the gradients\n",
        "    out = model(X) # Forward pass\n",
        "    loss = loss_function(out, y) # Calculate the loss\n",
        "    loss.backward() # Backpropagate the error\n",
        "    optimizer.step() # Update the weights\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss/len(train_loader)\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "  model.eval()\n",
        "  correct, total = 0, 0\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad():\n",
        "    for reviews, y in tqdm(val_loader,\"Validation\"):\n",
        "        # Calculate review embeddings dynamically (without gradient tracking for evaluation)\n",
        "        X = torch.stack([get_review_embedding(review) for review in reviews]).to(device)\n",
        "        y = y.to(device) # Move labels to device\n",
        "\n",
        "        out = model(X) # Forward pass\n",
        "        preds = torch.softmax(out, dim=1)  # Pass through softmax layer\n",
        "        preds = torch.argmax(preds, dim=1)  #Get prediction by doing argmax\n",
        "        correct += (preds == y).sum().item() # Check how many are correct\n",
        "        all_predictions.extend(preds.cpu().numpy()) # Save predictions\n",
        "        all_labels.extend(y.cpu().numpy()) # Save labels\n",
        "        total += y.size(0)\n",
        "  acc = correct / total\n",
        "  return acc, all_predictions, all_labels\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = train_model(SENT_MODEL, train_dataloader_imd)\n",
        "  validation_accuracy , predictions, labels= evaluate_model(SENT_MODEL, test_dataloader_imd)\n",
        "  print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "6Lm-IYgjYQdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate precision, recall and F-measure of our Sentiment Analysis model. Also plot Confusion Matrix"
      ],
      "metadata": {
        "id": "v4bKgugqAtuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# You have already a np.array of labels and predictions\n",
        "\n",
        "#TODO calculate precision, recall and F1 measure and print Confusion Matrix\n",
        "\n",
        "# Calculate precision, recall, and F1 measure\n",
        "precision = precision_score(labels, predictions, average='weighted')\n",
        "recall = recall_score(labels, predictions, average='weighted')\n",
        "f1 = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Measure: {f1:.4f}\")\n",
        "\n",
        "# Calculate and plot the confusion matrix\n",
        "cm = confusion_matrix(labels, predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DbCx4unQfSHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Experiment! ðŸ¤“\n",
        "\n",
        "Pick 3 of the following experiments and develop a solution **in this same notebook**. Take advange of the notebook structure to give a clear structure of experiment -> conclusions\n",
        "\n",
        "1. Compare with another pretrained word2vec model\n",
        "2. Experiment with a different sentiment analysis dataset (might require change in architecture of sentiment analyser)\n",
        "3. Train your CBOW model on a different train set (might require data preprocessing)\n",
        "4. Play with hyperparameters (window size, embedding dimension)\n"
      ],
      "metadata": {
        "id": "8069Ltpe6sQc"
      }
    }
  ]
}